#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Dec 26 13:06:31 2023

@author: ahmetnaim
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
veriler = pd.read_csv("output1 (copy).csv")
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, classification_report,auc)
scaler = StandardScaler()
from sklearn import svm
from sklearn.metrics import r2_score
import statsmodels.api as sm
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_predict
'''def normalize_ip_address_list(ip_addresses):
    # Her bir IP adresini normalize et
    normalized_ips = []

    sc = MinMaxScaler()
    for addr in ip_addresses:
        # IP adresini "." karakterine göre böl
        ip_parts = addr[0].split(".")
        
        
        
        # Normalizasyon işlemini uygula (Min-Max normalleme)
        normalized_ip = sc.fit_transform([list(map(int, ip_parts))]).flatten()
        
        # Normalleştirilmiş IP'yi listeye ekle
        normalized_ips.append(normalized_ip)
    
    return normalized_ips'''

def normalize_ip_address_list(ip_list):
    normalized_ips = []
    for addr in ip_list:
        if isinstance(addr, str):  # String olduğundan emin olun
            ip_parts = addr.split(".")
            normalized_ips.append(ip_parts[3])  # Sadece son basamağı al
        else:
            normalized_ips.append(addr)  # String değilse aynı değeri kullan
    return normalized_ips

from sklearn import preprocessing

protocol = veriler.iloc[7:156104,7:8].values
print(protocol)
one = preprocessing.OneHotEncoder()
protocol = one.fit_transform(protocol).toarray()
print (protocol)
service= veriler.iloc[7:156104,8:9].values
service = one.fit_transform(service).toarray()
print(service)
connstate = veriler.iloc[7:156104,12:13].values
connstate = one.fit_transform(connstate).toarray()
print(connstate)
history = veriler.iloc[7:156104,16:17].values
history = one.fit_transform(history).toarray()
print(history)
tunnelparents=veriler.iloc[7:156104,21:22].values
tunnelparents=one.fit_transform(tunnelparents).toarray()
print(tunnelparents)
label= veriler.iloc[7:156104,22:23].values
le=LabelEncoder()
label = le.fit_transform(label)
print(label)
ip = veriler.iloc[7:156104,6:7].values

ip =normalize_ip_address_list(ip)
ip = scaler.fit_transform(ip)
ip_dt = pd.DataFrame(ip)
print(ip)
veriler1 = veriler.iloc[7:156104,4:5].values
veriler1 = scaler.fit_transform(veriler1)
veriler2 = veriler.iloc[7:156104,9:12].values
veriler2 = scaler.fit_transform(veriler2)
veriler3 = veriler.iloc[7:156104,15:16].values
veriler3 = scaler.fit_transform(veriler3)
veriler4 = veriler.iloc[7:156104,17:21].values
veriler4 = scaler.fit_transform(veriler4)
protocol_dt = pd.DataFrame(protocol)
service_dt =pd.DataFrame(service)
connstate_dt = pd.DataFrame(connstate)
history_dt=pd.DataFrame(history)
label_dt = pd.DataFrame(label)
veriler1_dt = pd.DataFrame(veriler1)
veriler2_dt = pd.DataFrame(veriler2)
veriler3_dt = pd.DataFrame(veriler3)
veriler4_dt = pd.DataFrame(veriler4)
train_veri = pd.concat([veriler1_dt,ip_dt,protocol_dt,service_dt,veriler2_dt,connstate_dt,veriler3_dt,history_dt,veriler4_dt,label_dt],axis=1)
#trainveri = pd.concat([veriler1_dt,ip_dt,protocol_dt,service_dt,veriler2_dt,connstate_dt,veriler3_dt,history_dt,veriler4_dt,label_dt],axis=1)


#train_veri = scaler.fit_transform(trainveri.values.reshape(-1,1))

label_end = train_veri.iloc[:,97:].values
train_veri1 = train_veri.iloc[:,0:17]
train_veri2 = train_veri.iloc[:,18:23]
train_veri3 = train_veri.iloc[:,25:35]
train_veri4 = train_veri.iloc[:,40:41]
train_veri5 = train_veri.iloc[:,42:47]
train_veri6 = train_veri.iloc[:,49:50]
train_veri7 = train_veri.iloc[:,51:81]
train_veri8 = train_veri.iloc[:,82:88]
train_veri9 = train_veri.iloc[:,89:91]
train_veri10 = train_veri.iloc[:,93:98]

train_data_end = pd.concat([train_veri1,train_veri2,train_veri3,train_veri4,train_veri5,train_veri6,train_veri7,train_veri8,train_veri9,train_veri10],axis=1)

train_veri11 = train_data_end.iloc[:,:29]
train_veri12 = train_data_end.iloc[:,30:37]
train_veri13 = train_data_end.iloc[:,38:48]
train_veri14 = train_data_end.iloc[:,49:69]
train_veri15 = train_data_end.iloc[:,70:]
train_data_end = pd.concat([train_veri11,train_veri12,train_veri13,train_veri14,train_veri15],axis=1)

train_data_end1 = train_data_end.sample(frac=0.7,random_state=40)
label_dt_train = train_data_end1.iloc[:,77:].values
train_data_fit = train_data_end1.iloc[:,:77]
test_data = train_data_end.drop(train_data_end1.index)
test_data_train = test_data.iloc[:,:77]
test_label = test_data.iloc[:,77:].values

train_data_fit = train_data_fit.values
train_data_fold = train_data_end.iloc[:,:77].values
label_data_fold = train_data_end.iloc[:,77:].values
label_data_fold = label_data_fold.ravel()
train_data_fold = scaler.fit_transform(train_data_fold)
#train_veri2 = pd.concat(train_veri1,train_veri2,axis=1)

label_dt_train= label_dt_train.ravel()
from sklearn.model_selection import train_test_split
#x_train,x_test,y_train,y_test = train_test_split(train_veri1,train_veri2,test_size=0.33,random_state=0)

#x_test,y_test = train_test_split(train_data_fit,label_dt_train,test_size=1,random_state=0)
X_train1 = scaler.fit_transform(train_data_fit)#fit öğrenme fonksiyonunu çalıştıtrıyor
X_test1 = scaler.transform(test_data_train)#öğrenilen bilgiyi direk deniyor
test_data_train = scaler.fit_transform(test_data_train)
testlabel = X_test1
print("----------------LR--------------------")
expected = testlabel
regressor = LogisticRegression(random_state=0)
regressor.fit(X_train1, label_dt_train)
pred = regressor.predict(X_test1)
proba = regressor.predict_proba(X_test1)
y_train1 = expected
y_pred = pred
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_label,y_pred)
print(cm)
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(regressor,train_data_fold , label_data_fold, cv=kf)
y_pred1 = cross_val_predict(regressor,train_data_fold , label_data_fold, cv=kf)
for i, (train_index, test_index) in enumerate(kf.split(train_data_fit, label_dt_train)):
    X_train, X_test = train_data_fit[train_index], train_data_fit[test_index]
    y_train, y_test = label_dt_train[train_index], label_dt_train[test_index]
    
    regressor.fit(X_train, y_train)
    y_pred_iter = regressor.predict(X_test)
    
    cm_iter = confusion_matrix(y_test, y_pred_iter)
    print(f"Confusion Matrix - Iteration {i + 1}:\n{cm_iter}\n")
print(scores)
model=sm.OLS(regressor.predict(X_test1),X_test1)
print(model.fit().summary())
print('Linear R2 degeri')
print(r2_score(label_dt_train, regressor.predict(X_train1)))
accuracy = accuracy_score(test_label, y_pred)
recall = recall_score(test_label, y_pred , average="binary")
precision = precision_score(test_label, y_pred , average="binary")
f1 = f1_score(test_label, y_pred, average="binary")

print("accuracy")
print("%.10f" %accuracy)
print("precision")
print("%.10f" %precision)
print("racall")
print("%.10f" %recall)
print("f1score")
print("%.10f" %f1)

print("----------SVM--------------")
model = svm.SVC(kernel='rbf', C=1000,probability=True,random_state=0)
model.fit(X_train1,label_dt_train)
# make predictions

pred = model.predict(X_test1)
proba = model.predict_proba(X_test1)


y_pred = pred
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_label,y_pred)
print(cm)
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(model,train_data_fold , label_data_fold, cv=kf)
y_pred1 = cross_val_predict(model,train_data_fold , label_data_fold, cv=kf)
for i, (train_index, test_index) in enumerate(kf.split(train_data_fit, label_dt_train)):
    X_train, X_test = train_data_fit[train_index], train_data_fit[test_index]
    y_train, y_test = label_dt_train[train_index], label_dt_train[test_index]
    
    model.fit(X_train, y_train)
    y_pred_iter = model.predict(X_test)
    
    cm_iter = confusion_matrix(y_test, y_pred_iter)
    print(f"Confusion Matrix - Iteration {i + 1}:\n{cm_iter}\n")
# X_train = X_train[:len(X_test)]
# y_train = y_train[:len(X_test)]
accuracy = accuracy_score(test_label, y_pred)
recall = recall_score(test_label, y_pred , average="binary")
precision = precision_score(test_label, y_pred , average="binary")
f1 = f1_score(test_label, y_pred, average="binary")

print("accuracy")
print("%.10f" %accuracy)
print("precision")
print("%.10f" %precision)
print("racall")
print("%.10f" %recall)
print("f1score")
print("%.10f" %f1)

print('----------KNN-------')


model = KNeighborsClassifier()
model.fit(X_train1, label_dt_train)
pred = model.predict(X_test1)
proba = model.predict_proba(X_test1)
y_pred = pred
cm = confusion_matrix(test_label,y_pred)
print(cm)
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(model,train_data_fold , label_data_fold, cv=kf)
y_pred1 = cross_val_predict(model,train_data_fold , label_data_fold, cv=kf)
for i, (train_index, test_index) in enumerate(kf.split(train_data_fold, label_data_fold)):
    X_train, X_test = train_data_fold[train_index], train_data_fold[test_index]
    y_train, y_test = label_data_fold[train_index], label_data_fold[test_index]
    
    model.fit(X_train, y_train)
    y_pred_iter = model.predict(X_test)
    
    cm_iter = confusion_matrix(y_test, y_pred_iter)
    print(f"Confusion Matrix - Iteration {i + 1}:\n{cm_iter}\n")
accuracy = accuracy_score(test_label, y_pred)
recall = recall_score(test_label, y_pred , average="binary")
precision = precision_score(test_label, y_pred , average="binary")
f1 = f1_score(test_label, y_pred, average="binary")

print("accuracy")
print("%.10f" %accuracy)
print("precision")
print("%.10f" %precision)
print("racall")
print("%.10f" %recall)
print("f1score")
print("%.10f" %f1)
